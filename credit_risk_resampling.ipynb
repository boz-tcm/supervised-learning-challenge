{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Classification\n",
    "\n",
    "Credit risk poses a classification problem that’s inherently imbalanced. This is because healthy loans easily outnumber risky loans. In this Challenge, you’ll use various techniques to train and evaluate models with imbalanced classes. You’ll use a dataset of historical lending activity from a peer-to-peer lending services company to build a model that can identify the creditworthiness of borrowers.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "This challenge consists of the following subsections:\n",
    "\n",
    "* Split the Data into Training and Testing Sets\n",
    "\n",
    "* Create a Logistic Regression Model with the Original Data\n",
    "\n",
    "* Predict a Logistic Regression Model with Resampled Training Data \n",
    "\n",
    "### Split the Data into Training and Testing Sets\n",
    "\n",
    "Open the starter code notebook and then use it to complete the following steps.\n",
    "\n",
    "1. Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame.\n",
    "\n",
    "2. Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns.\n",
    "\n",
    "    > **Note** A value of `0` in the “loan_status” column means that the loan is healthy. A value of `1` means that the loan has a high risk of defaulting.  \n",
    "\n",
    "3. Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "\n",
    "4. Split the data into training and testing datasets by using `train_test_split`.\n",
    "\n",
    "### Create a Logistic Regression Model with the Original Data\n",
    "\n",
    "Employ your knowledge of logistic regression to complete the following steps:\n",
    "\n",
    "1. Fit a logistic regression model by using the training data (`X_train` and `y_train`).\n",
    "\n",
    "2. Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model.\n",
    "\n",
    "3. Evaluate the model’s performance by doing the following:\n",
    "\n",
    "    * Calculate the accuracy score of the model.\n",
    "\n",
    "    * Generate a confusion matrix.\n",
    "\n",
    "    * Print the classification report.\n",
    "\n",
    "4. Answer the following question: How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "### Predict a Logistic Regression Model with Resampled Training Data\n",
    "\n",
    "Did you notice the small number of high-risk loan labels? Perhaps, a model that uses resampled data will perform better. You’ll thus resample the training data and then reevaluate the model. Specifically, you’ll use `RandomOverSampler`.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. \n",
    "\n",
    "2. Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions.\n",
    "\n",
    "3. Evaluate the model’s performance by doing the following:\n",
    "\n",
    "    * Calculate the accuracy score of the model.\n",
    "\n",
    "    * Generate a confusion matrix.\n",
    "\n",
    "    * Print the classification report.\n",
    "    \n",
    "4. Answer the following question: How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "### Write a Credit Risk Analysis Report\n",
    "\n",
    "For this section, you’ll write a brief report that includes a summary and an analysis of the performance of both machine learning models that you used in this challenge. You should write this report as the `README.md` file included in your GitHub repository.\n",
    "\n",
    "Structure your report by using the report template that `Starter_Code.zip` includes, and make sure that it contains the following:\n",
    "\n",
    "1. An overview of the analysis: Explain the purpose of this analysis.\n",
    "\n",
    "\n",
    "2. The results: Using bulleted lists, describe the balanced accuracy scores and the precision and recall scores of both machine learning models.\n",
    "\n",
    "3. A summary: Summarize the results from the machine learning models. Compare the two versions of the dataset predictions. Include your recommendation for the model to use, if any, on the original vs. the resampled data. If you don’t recommend either model, justify your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77536 entries, 0 to 77535\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   loan_size         77536 non-null  float64\n",
      " 1   interest_rate     77536 non-null  float64\n",
      " 2   borrower_income   77536 non-null  int64  \n",
      " 3   debt_to_income    77536 non-null  float64\n",
      " 4   num_of_accounts   77536 non-null  int64  \n",
      " 5   derogatory_marks  77536 non-null  int64  \n",
      " 6   total_debt        77536 non-null  int64  \n",
      " 7   loan_status       77536 non-null  int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 4.7 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77531</th>\n",
       "      <td>19100.0</td>\n",
       "      <td>11.261</td>\n",
       "      <td>86600</td>\n",
       "      <td>0.653580</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>56600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77532</th>\n",
       "      <td>17700.0</td>\n",
       "      <td>10.662</td>\n",
       "      <td>80900</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77533</th>\n",
       "      <td>17600.0</td>\n",
       "      <td>10.595</td>\n",
       "      <td>80300</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77534</th>\n",
       "      <td>16300.0</td>\n",
       "      <td>10.068</td>\n",
       "      <td>75300</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77535</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>9.742</td>\n",
       "      <td>72300</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>42300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "0        10700.0          7.672            52800        0.431818   \n",
       "1         8400.0          6.692            43600        0.311927   \n",
       "2         9000.0          6.963            46100        0.349241   \n",
       "3        10700.0          7.664            52700        0.430740   \n",
       "4        10800.0          7.698            53000        0.433962   \n",
       "...          ...            ...              ...             ...   \n",
       "77531    19100.0         11.261            86600        0.653580   \n",
       "77532    17700.0         10.662            80900        0.629172   \n",
       "77533    17600.0         10.595            80300        0.626401   \n",
       "77534    16300.0         10.068            75300        0.601594   \n",
       "77535    15600.0          9.742            72300        0.585062   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  loan_status  \n",
       "0                    5                 1       22800            0  \n",
       "1                    3                 0       13600            0  \n",
       "2                    3                 0       16100            0  \n",
       "3                    5                 1       22700            0  \n",
       "4                    5                 1       23000            0  \n",
       "...                ...               ...         ...          ...  \n",
       "77531               12                 2       56600            1  \n",
       "77532               11                 2       50900            1  \n",
       "77533               11                 2       50300            1  \n",
       "77534               10                 2       45300            1  \n",
       "77535                9                 2       42300            1  \n",
       "\n",
       "[77536 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "# Standardize the file path\n",
    "file_nm_path = Path('Resources/lending_data.csv')\n",
    "# Read the CSV file into a DataFrame\n",
    "lending_data_df = pd.read_csv(file_nm_path)\n",
    "\n",
    "# Review the DataFrame\n",
    "display(lending_data_df.info(), lending_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "\n",
    "# The label is the dependent discrete binary variable, y, representing loan status, where y == 0 for a healthy loan, and y == 1 for an impaired loan\n",
    "# Separate the y variable, the labels\n",
    "y = lending_data_df['loan_status']\n",
    "#display(y.info(), y) # Pandas Series\n",
    "\n",
    "# The features are the independent variables, collectively X, or the explanatory variables, or predictors\n",
    "# Separate the X variable, the features\n",
    "X = lending_data_df.drop(columns=['loan_status'])\n",
    "#display(X.info(), X) # Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 77536 entries, 0 to 77535\n",
      "Series name: loan_status\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "77536 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 605.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "77531    1\n",
       "77532    1\n",
       "77533    1\n",
       "77534    1\n",
       "77535    1\n",
       "Name: loan_status, Length: 77536, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the y variable Series\n",
    "display(y.info(), y) # Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77536 entries, 0 to 77535\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   loan_size         77536 non-null  float64\n",
      " 1   interest_rate     77536 non-null  float64\n",
      " 2   borrower_income   77536 non-null  int64  \n",
      " 3   debt_to_income    77536 non-null  float64\n",
      " 4   num_of_accounts   77536 non-null  int64  \n",
      " 5   derogatory_marks  77536 non-null  int64  \n",
      " 6   total_debt        77536 non-null  int64  \n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 4.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77531</th>\n",
       "      <td>19100.0</td>\n",
       "      <td>11.261</td>\n",
       "      <td>86600</td>\n",
       "      <td>0.653580</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>56600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77532</th>\n",
       "      <td>17700.0</td>\n",
       "      <td>10.662</td>\n",
       "      <td>80900</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77533</th>\n",
       "      <td>17600.0</td>\n",
       "      <td>10.595</td>\n",
       "      <td>80300</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77534</th>\n",
       "      <td>16300.0</td>\n",
       "      <td>10.068</td>\n",
       "      <td>75300</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>45300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77535</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>9.742</td>\n",
       "      <td>72300</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>42300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "0        10700.0          7.672            52800        0.431818   \n",
       "1         8400.0          6.692            43600        0.311927   \n",
       "2         9000.0          6.963            46100        0.349241   \n",
       "3        10700.0          7.664            52700        0.430740   \n",
       "4        10800.0          7.698            53000        0.433962   \n",
       "...          ...            ...              ...             ...   \n",
       "77531    19100.0         11.261            86600        0.653580   \n",
       "77532    17700.0         10.662            80900        0.629172   \n",
       "77533    17600.0         10.595            80300        0.626401   \n",
       "77534    16300.0         10.068            75300        0.601594   \n",
       "77535    15600.0          9.742            72300        0.585062   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  \n",
       "0                    5                 1       22800  \n",
       "1                    3                 0       13600  \n",
       "2                    3                 0       16100  \n",
       "3                    5                 1       22700  \n",
       "4                    5                 1       23000  \n",
       "...                ...               ...         ...  \n",
       "77531               12                 2       56600  \n",
       "77532               11                 2       50900  \n",
       "77533               11                 2       50300  \n",
       "77534               10                 2       45300  \n",
       "77535                9                 2       42300  \n",
       "\n",
       "[77536 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the X variable DataFrame\n",
    "display(X.info(), X) # Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y labels count:\n",
      "0    75036\n",
      "1     2500\n",
      "Name: loan_status, dtype: int64\n",
      "\n",
      "y labels weight distribution:\n",
      "0    0.967757\n",
      "1    0.032243\n",
      "Name: loan_status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y_labels_count = y.value_counts()\n",
    "y_labels_distribution = y.value_counts(normalize=True)\n",
    "print(f\"y labels count:\\n{y_labels_count}\\n\\ny labels weight distribution:\\n{y_labels_distribution}\")\n",
    "# The target class majority label to minority label skew is about 30-to-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function.  # Assigning a random state is recommended for purposes of reproducibility.\n",
    "# 'stratify=y' ensures that train and test datasets each preserve the label proportion from the original dataset. The default, otherwise, is 'None'.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1, solver='liblinear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "# Selecting 'liblinear' as solver given simple classification: single binomial class.  Liblinear supports both L1 and L2 regularization.\n",
    "lending_logistic_regression_model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "lending_logistic_regression_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a prediction using the testing data\n",
    "lending_test_predictions = lending_logistic_regression_model.predict(X_test)\n",
    "display(len(lending_test_predictions), lending_test_predictions) # 'test' array size verified as 25% of original dataset, generated through train_test_split's default split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance, or classification accuracy, by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/bozmbp18/Tresorit/Boz & Company LLC/IAR/Todd Meier/Education/Columbia Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_12/Homework/supervised-learning-challenge/credit_risk_resampling.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_12/Homework/supervised-learning-challenge/credit_risk_resampling.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a DataFrame for the test results and inspect prediction of loan health versus actual health (High_Risk_Loan==1)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_12/Homework/supervised-learning-challenge/credit_risk_resampling.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lending_test_results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mlending test predictions\u001b[39m\u001b[39m'\u001b[39m: lending_test_predictions, \u001b[39m'\u001b[39m\u001b[39mactuals\u001b[39m\u001b[39m'\u001b[39m: y_test})\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_12/Homework/supervised-learning-challenge/credit_risk_resampling.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m display(lending_test_results_df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_12/Homework/supervised-learning-challenge/credit_risk_resampling.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Print the 'balanced_accuracy_score' for the model's test data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the test results and inspect prediction of loan health versus actual health (High_Risk_Loan==1)\n",
    "lending_test_results_df = pd.DataFrame({'lending test predictions': lending_test_predictions, 'actuals': y_test}).reset_index(drop=True)\n",
    "display(lending_test_results_df)\n",
    "\n",
    "# Print the 'balanced_accuracy_score' for the model's test data\n",
    "lending_test_balanced_accuracy_score = balanced_accuracy_score(y_test, lending_test_predictions)\n",
    "print(f\"Balanced accuracy score for model's test data: {lending_test_balanced_accuracy_score}\")\n",
    "\n",
    "# Print the traditional 'accuracy_score' for the model's test data for comparison to the 'balanced_accuracy_score version'\n",
    "lending_test_accuracy_score = accuracy_score(y_test, lending_test_predictions)\n",
    "print(f\"Traditional accuracy score for model's test data: {lending_test_accuracy_score}\")\n",
    "\n",
    "print(\"\\nVery interesting: if the dataset was balanced, the traditional 'accuracy_score' by definition would equal the 'balanced_accuracy_score'.  \\n\\\n",
    "In this case, the 'balanced_accuracy_score' is materially less than the traditional 'accuracy_score', consistent with our observation of an imbalanced dataset.  \\n\\\n",
    "The 'balanced_accuracy_score' accounts for imbalanced datasets by weighting each sample by the inverse prevalence of its true class,  \\n\\\n",
    "c.f. https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18678    81]\n",
      " [   62   563]]\n",
      "\n",
      "confusion matrix components:\n",
      "true negatives: 18678, false positives: 81, false negatives: 62, true positives: 563\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "lending_test_confusion_matrix = confusion_matrix(y_test, lending_test_predictions, labels = [0, 1]) # Method input order actuals, predictions.  Healthy_Loan==0, High_Risk_Loan==1.\n",
    "tn, fp, fn, tp = lending_test_confusion_matrix.ravel() # Ravel() creates one-dimensional array faster than reshape() method\n",
    "print(lending_test_confusion_matrix)\n",
    "print(f\"\\nconfusion matrix components:\\ntrue negatives: {tn}, false positives: {fp}, false negatives: {fn}, true positives: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Taking Into Account Imbalanced Loan Status Class:\n",
      "                      pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  Healthy Loan       1.00      1.00      0.90      1.00      0.95      0.91     18759\n",
      "High-Risk Loan       0.87      0.90      1.00      0.89      0.95      0.89       625\n",
      "\n",
      "   avg / total       0.99      0.99      0.90      0.99      0.95      0.90     19384\n",
      "\n",
      "\n",
      "Traditional Classification Report Without Taking Into Account Loan Status Class Imbalance:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Healthy Loan       1.00      1.00      1.00     18759\n",
      "High-Risk Loan       0.87      0.90      0.89       625\n",
      "\n",
      "      accuracy                           0.99     19384\n",
      "     macro avg       0.94      0.95      0.94     19384\n",
      "  weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define labels for use in classification reports\n",
    "target_labels = ['Healthy Loan', 'High-Risk Loan']\n",
    "\n",
    "# Print the classification report for the model\n",
    "lending_test_imbalanced_classification_report = classification_report_imbalanced(y_test, lending_test_predictions, target_names=target_labels) \n",
    "print(f\"Classification Report Taking Into Account Imbalanced Loan Status Class:\\n{lending_test_imbalanced_classification_report}\\n\")\n",
    "\n",
    "# Print the traditional 'classification_report' for the model's test data for comparison to the 'classification_report_imbalanced' version\n",
    "lending_test_classification_report = classification_report(y_test, lending_test_predictions, target_names=target_labels) \n",
    "print(f\"Traditional Classification Report Without Taking Into Account Loan Status Class Imbalance:\\n{lending_test_classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** `The test dataset loan status class is imbalanced, with just 625 loans labeled 'high-risk', while 18759 loans are labeled 'healthy'.  Therefore, traditional accuracy measure, defined as the ratio of total CORRECT predictions to total predictions [(TP+TN)/(P+N)] could indicate a high level of model accuracy for a model that only predicts the majority class label, in this case 'healthy loan', obscuring a bad model that does not address its objective of predicting the minority class label 'high-risk loan'.  In other words, a model that by traditional measures appears highly accurate yet has no ability to predict high-risk loans, or differentiate between healthy and high-risk loans.`\n",
    "\n",
    "`According to Brownlee (2021), for imbalanced datasets, two metric pairs mitigate bias when evaluating imbalanced dataset models: sensitivity-specificity and recall-precision:`\n",
    "- `Sensitivity-Specificity pairing:`\n",
    "- `\"For imbalanced classification, the sensitivity [or recall] might be more interesting than the specificity.\"`\n",
    "- `\"Sensitivity and Specificity can be combined into a single score that balances both concerns, called the geometric mean or G-Mean: G-Mean = sqrt(Sensitivity * Specificity)\"`\n",
    "- - `Recall-Precision pairing:`\n",
    "- `\"Precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score or the F-measure: F-Measure = (2 * Precision * Recall) / (Precision + Recall)\"`\n",
    "- `\"The F-Measure is a popular metric for imbalanced classification.\"`\n",
    "    - `c.f. Brownlee, Jason, 2021, \"Tour of Evaluation Metrics for Imbalanced Classification\",` https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification\n",
    "- `Furthermore, Jayaswal (2020), notes that the F-score \"is the harmonic mean of precision and recall. It takes both false positive[s] and false negatives into account. Therefore, it performs well on an imbalanced dataset\" and \"gives the same weightage to recall and precision\", although there are also F-score versions where the weightage varies by a beta parameter used to say how many more times recall is important than precision, for example a beta of 2 is used to indicate recall is twice as important as precision when evaluating or comparing models.`\n",
    "    - `c.f. Jayaswal, Vaibhav, 2020, \"Performance Metrics: Confusion matrix, Precision, Recall, and F1 Score: Unraveling the Confusion Behind the Confusion Matrix\",` https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262\n",
    "\n",
    "`According to scikit-learn.org, the balanced accuracy score function computes the balanced accuracy, which avoids inflated performance estimates on imbalanced datasets. It is the macro-average of recall scores per class or,` *`equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class.`* (italics emphasis added)\n",
    "- c.f. https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score\n",
    "\n",
    "`And according to statology.org, balanced accuracy is the macro average (aka arithmetic mean) of sensitivity (or true positive rate, or recall on the positive class label) and specificity (true negative rate, or recall on the negative class label):`\n",
    "- `balanced accuracy = (sensitivity + specificity) / 2`\n",
    "    - c.f. https://www.statology.org/balanced-accuracy\n",
    "\n",
    "`A similar measure to balanced accuracy is the geometric mean, which is the geometric mean, as opposed to the arithmetic mean, of recall (or sensitivity) and specificity:`\n",
    "- `geometric mean accuracy measure, used in the imbalanced classification report = sqrt(sensitivity * specificity)`\n",
    "- `Note the geometric mean mathematically converges to the arithmetic mean as sensitivity and specificity become closer to one another, and the two means are identical by definition when sensitivity equals specificity`\n",
    "    - `c.f. Anand, Aman, 2021, \"Performance measures for Imbalanced Classes\",` https://dev.to/amananandrai/performance-measures-for-imbalanced-classes-2ojj\n",
    "\n",
    "`The imbalanced classification report also includes a newer metric for measuring accuracy of imbalanced dataset models called the Index of Balanced Accuracy (IBA) reported in a 2009 academic paper:`\n",
    "- `index balanced accuracy (iba) = (1 + α*Dominance)(GMean²), where Dominance is the true positive rate less the true negative rate, or recall - specificity, and GMean² is the geometric mean-squared, or the product of recall and specificity.  The weight assigned to Dominance is α, where the default for the imbalanced classification report is 0.1.  \"The closer the Dominance is to 0, the more balanced both individual rates are.  In practice, Dominance can be interpreted as an indicator of how balanced the TPrate and the TNrate are.\"  (Garcia, 2009).`\n",
    "    - `c.f. Garcia et al., 2009, \"Index of Balanced Accuracy: A Performance Measure for Skewed Class Distributions\",` https://core.ac.uk/download/pdf/61392839.pdf\n",
    "    - `c.f. Anand, Aman, 2021, \"Performance measures for Imbalanced Classes\",` https://dev.to/amananandrai/performance-measures-for-imbalanced-classes-2ojj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomOverSampler module form imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler algo object.  The strategy here is therefore to randomly oversample, or duplicate, the minority class label (high-risk loans)\n",
    "# Assign a random_state parameter of 1 to the model.  random_state is the seed used by the random number generator, for replication and validation purposes\n",
    "rand_oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random oversampler algo object, creating the oversampled, or resampled, training data model (algo + data = model)\n",
    "# The change to the class label distribution is only applied to the original training data, not the test data, which is used ultimately to evaluate the performance of the model\n",
    "X_train_resampled, y_train_resampled = rand_oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train labels resampled count:\n",
      "0    56277\n",
      "1    56277\n",
      "Name: loan_status, dtype: int64\n",
      "\n",
      "y_train labels resampled weight distribution:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: loan_status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the distinct values of the resampled labels data\n",
    "y_train_labels_resampled_count = y_train_resampled.value_counts()\n",
    "y_train_labels_resampled_distribution = y_train_resampled.value_counts(normalize=True)\n",
    "print(f\"y_train labels resampled count:\\n{y_train_labels_resampled_count}\\n\\ny_train labels resampled weight distribution:\\n{y_train_labels_resampled_distribution}\")\n",
    "# The resampled train target class majority label to minority label skew is now about 1-to-1, down from around 30-to-1! before random oversampling of the original train minority class label\n",
    "# The downside to random oversampling of the original minority class label is the introduction of overfitting bias in the train data model used in subsequent prediction.\n",
    "# The minority train class label has now been inflated roughly 30 times through random duplication of values from the original train minority label, while not preserving the original minority sample variance, \\n\n",
    "# inferring greater certainty in the minority class than originally observed, leading to overfitting bias in subsequent prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate another Logistic Regression model object to be used with the resampled data\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "# Selecting 'liblinear' as solver given simple classification: single binomial class.  Liblinear supports both L1 and L2 regularization.\n",
    "lending_resampled_logistic_regression_model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "lending_resampled_logistic_regression_model.fit(X=X_train_resampled, y=y_train_resampled)\n",
    "\n",
    "# Make a new prediction using the testing data following model fit to resampled train data \n",
    "lending_resampled_model_test_predictions = lending_resampled_logistic_regression_model.predict(X_test)\n",
    "display(len(lending_resampled_model_test_predictions), lending_resampled_model_test_predictions) # 'test' array size verified as unchanged: 25% of original dataset, generated through train_test_split's default split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score for model's test data: 0.9959744975744975\n",
      "Traditional accuracy score for model's test data: 0.9952022286421791\n"
     ]
    }
   ],
   "source": [
    "# Print the 'balanced_accuracy_score' for the resampled model's test data\n",
    "lending_resampled_test_balanced_accuracy_score = balanced_accuracy_score(y_test, lending_resampled_model_test_predictions)\n",
    "print(f\"Balanced accuracy score for model's test data: {lending_resampled_test_balanced_accuracy_score}\")\n",
    "\n",
    "# Print the traditional 'accuracy_score' for the resampled model's test data for comparison to the 'balanced_accuracy_score version'\n",
    "lending_resampled_test_accuracy_score = accuracy_score(y_test, lending_resampled_model_test_predictions)\n",
    "print(f\"Traditional accuracy score for model's test data: {lending_resampled_test_accuracy_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampled model confusion matrix:\n",
      "[[18668    91]\n",
      " [    2   623]]\n",
      "\n",
      "resampled model confusion matrix components:\n",
      "true negatives: 18668, false positives: 91, false negatives: 2, true positives: 623\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the resampled model\n",
    "lending_resampled_test_confusion_matrix = confusion_matrix(y_test, lending_resampled_model_test_predictions, labels = [0, 1]) # Method input order actuals, predictions.  Healthy_Loan==0, High_Risk_Loan==1.\n",
    "tn_resampled, fp_resampled, fn_resampled, tp_resampled = lending_resampled_test_confusion_matrix.ravel() # Ravel() creates one-dimensional array faster than reshape() method\n",
    "print(f\"resampled model confusion matrix:\\n{lending_resampled_test_confusion_matrix}\")\n",
    "print(f\"\\nresampled model confusion matrix components:\\ntrue negatives: {tn_resampled}, false positives: {fp_resampled}, false negatives: {fn_resampled}, true positives: {tp_resampled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Classification Report for Resampled Model:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Healthy Loan       1.00      1.00      1.00     18759\n",
      "High-Risk Loan       0.87      1.00      0.93       625\n",
      "\n",
      "      accuracy                           1.00     19384\n",
      "     macro avg       0.94      1.00      0.96     19384\n",
      "  weighted avg       1.00      1.00      1.00     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define labels for use in resampled model classification report\n",
    "target_labels = ['Healthy Loan', 'High-Risk Loan']\n",
    "\n",
    "# Print the traditional 'classification_report' for the resampled model's test predictions\n",
    "lending_resampled_test_classification_report = classification_report(y_test, lending_resampled_model_test_predictions, target_names=target_labels) \n",
    "print(f\"Traditional Classification Report for Resampled Model:\\n{lending_resampled_test_classification_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** YOUR ANSWER HERE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
